{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Qi6cczbQ7J1WxSkPWbtnMhSMARGb8LJ0",
      "authorship_tag": "ABX9TyPX+vQJzc92rgEF6fe0gnDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JarikDev/home_work_4/blob/main/%D0%93%D0%B0%D1%82%D0%B8%D0%BD%D1%81%D0%BA%D0%B8%D0%B9_%D0%AF_%D0%90_%D0%94%D0%97_PYTHON_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8qlnSeNVi2c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# старт таймера\n",
        "start_time = time.time()\n",
        "desired_width = 320\n",
        "pd.set_option('display.width', desired_width)\n",
        "np.set_printoptions(linewidth=desired_width)\n",
        "pd.set_option('display.max_columns', 20)\n",
        "\n",
        "\n",
        "# функция замеряет время от переданного аргументом старта\n",
        "def return_execution_time(start):\n",
        "    return time.time() - start\n",
        "\n",
        "\n",
        "# класс, который поможет нам сделать базовую аналитику по датафреймам\n",
        "class DataFrameAnalyzer:\n",
        "    def __init__(self, *dataframes):\n",
        "        self.__dataframes = dataframes\n",
        "\n",
        "    # статический метод описывает инфо по датафрейму\n",
        "    @staticmethod\n",
        "    def __show_df_info(df):\n",
        "        print(f\"Датафрейм {df.name} содержит {len(df.columns)} колонок\")\n",
        "        print(f\"Датафрейм {df.name} содержит следующие колонки {df.columns.values}\")\n",
        "        print(f\"Подробная информация по датафрейму {df.name}\")\n",
        "        print(df.info())\n",
        "\n",
        "    # метод возвращает первые пять строк датафрейма\n",
        "    @staticmethod\n",
        "    def __show_df_heads(df):\n",
        "        print(f\"Первые пять строк датафрейма {df.name}\")\n",
        "        print(df.head())\n",
        "\n",
        "    # метод показывает форма датафрейма\n",
        "    @staticmethod\n",
        "    def __show_df_shapes(df):\n",
        "        print(f\"Датафрейм {df.name} имеет форму {df.shape}\")\n",
        "\n",
        "    # метод описывает описательные характеристики датафрейма\n",
        "    @staticmethod\n",
        "    def __show_df_described_info(df):\n",
        "        print(f\"Данные датафрейма {df.name} имеют следующие характеристики:\")\n",
        "        described_info = df.describe()\n",
        "        # берём колонки\n",
        "        columns = described_info.columns.values\n",
        "        # итерируется по колонкам и выводим информацию\n",
        "        for c in columns:\n",
        "            print(f\"Для колонки {c} количество непустых строк {described_info[c].count()}\")\n",
        "            print(f\"Для колонки {c} общее количество записей {described_info[c].mean()}\")\n",
        "            print(f\"Для колонки {c} стандартное отклонение {described_info[c].std()}\")\n",
        "            q25 = described_info[c].loc[\"25%\"]\n",
        "            print(f\"Для колонки {c} общее количество записей в первый квартиль {q25}\")\n",
        "            q50 = described_info[c].loc[\"50%\"]\n",
        "            print(f\"Для колонки {c} общее количество записей в третий квартиль {q50}\")\n",
        "            q75 = described_info[c].loc[\"75%\"]\n",
        "            print(f\"Для колонки {c} общее количество записей попавших в четвёртый квартиль {q75}\")\n",
        "            print(f\"Для колонки {c} минимальное значение {described_info[c].min()}\")\n",
        "            print(f\"Для колонки {c} максимальное значение {described_info[c].max()}\")\n",
        "\n",
        "        print(f\"Данные датафрейма {df.name} колонки с типом object имеют следующие характеристики:\")\n",
        "        described_info = df.describe(include=['object'])\n",
        "        # берём колонки с типом обжэект и выводим информацию\n",
        "        columns = described_info.columns.values\n",
        "        for c in columns:\n",
        "            print(f\"Для колонки {c} количество непустых строк {described_info[c]['count']}\")\n",
        "            print(f\"Для колонки {c} количество уникальных значений {described_info[c]['unique']}\")\n",
        "            print(f\"Для колонки {c} самое частое значение - мода {described_info[c].top}\")\n",
        "            print(f\"Для колонки {c} частота  {described_info[c].freq}\")\n",
        "\n",
        "    # метод описывает количественные характеристики уникальных полей датафрейма\n",
        "    @staticmethod\n",
        "    def __show_df_unique_values(df):\n",
        "        print(f\"Проведём анализ уникальных значений в датафрейме {df.name}\")\n",
        "        columns = df.columns.values\n",
        "        for c in columns:\n",
        "            uniques = df[c].value_counts()\n",
        "            for k, v in uniques.items():\n",
        "                print(f\"В колонке {c} значения {k} встречается {v} раз\")\n",
        "\n",
        "    # метод выводит пропуски в данных, если они есть\n",
        "    @staticmethod\n",
        "    def __show_df_empties(df):\n",
        "        print(f\"Проведём анализ пустых значений в датафрейме {df.name}\")\n",
        "        print(df.isnull().sum())\n",
        "\n",
        "    # метод проводит подробный анализ датафрейма\n",
        "    def perform_analysis(self):\n",
        "        for df in self.__dataframes:\n",
        "            print(f\"##### Анализ датафрейма {df.name} #####\")\n",
        "            self.__show_df_info(df)\n",
        "            self.__show_df_shapes(df)\n",
        "            self.__show_df_heads(df)\n",
        "            self.__show_df_empties(df)\n",
        "            self.__show_df_described_info(df)\n",
        "            # next operation is very slow.\n",
        "            # self.__show_df_unique_values(df)\n",
        "\n",
        "\n",
        "# загружаем датафреймы и присваиваем им имена\n",
        "ld = pd.read_csv('/content/drive/MyDrive/hw4/c_lectures.csv', sep=',')\n",
        "ld.name = \"lectures_data\"\n",
        "qd = pd.read_csv('/content/drive/MyDrive/hw4/c_questions.csv', sep=',')\n",
        "qd.name = \"questions_data\"\n",
        "td = pd.read_csv('/content/drive/MyDrive/hw4/c_train.csv', sep=',')\n",
        "td.name = \"train_data\"\n",
        "analyzer = DataFrameAnalyzer(ld, qd, td)\n",
        "# проводим анализ датафреймов\n",
        "analyzer.perform_analysis()\n",
        "\n",
        "# заполняем пропуски в датафреймах\n",
        "qd[\"tags\"].replace([0], np.nan)\n",
        "td_min_prior_question_elapsed_time = td[\"prior_question_elapsed_time\"].min()\n",
        "td[\"prior_question_elapsed_time\"] = td[\"prior_question_elapsed_time\"].astype('float64')\n",
        "td[\"prior_question_elapsed_time\"] = td[\"prior_question_elapsed_time\"].replace(np.nan,\n",
        "                                                                              td_min_prior_question_elapsed_time)\n",
        "td[\"prior_question_had_explanation\"] = td[\"prior_question_had_explanation\"].astype('bool')\n",
        "\n",
        "# собираем всё в один датафрейм\n",
        "merged_df = pd.merge(td, qd, left_on='content_id', right_on='question_id')\n",
        "merged_df = pd.merge(merged_df, ld, left_on='content_id', right_on='lecture_id')\n",
        "merged_df.name = \"merged_df\"\n",
        "analyzer = DataFrameAnalyzer(merged_df)\n",
        "# проводим анализ получившегося датафрейма\n",
        "analyzer.perform_analysis()\n",
        "\n",
        "# 1. анализируем успеваемость студентов\n",
        "# 1 - ответ верный, 0 - нет, -1 - лекция\n",
        "# создаём себе вспомогательные кортежи для фильтрации датафреймов\n",
        "is_question_answer = (merged_df['answered_correctly'] == 1)\n",
        "is_correct = (merged_df['answered_correctly'] == 1)\n",
        "is_incorrect = (merged_df['answered_correctly'] == 0)\n",
        "is_lecture = (merged_df['answered_correctly'] == -1)\n",
        "is_question = (merged_df['answered_correctly'] != -1)\n",
        "\n",
        "# собираем статистику по ответам пользователя\n",
        "user_answer_stat = pd.DataFrame({\"user_id\": merged_df[\"user_id\"].unique()})\n",
        "\n",
        "# собираем уникальные айди пользователя\n",
        "user_ids = merged_df[\"user_id\"].unique()\n",
        "# собираем данные о правильных ответах\n",
        "correct_answers = merged_df[is_correct][[\"user_id\", \"answered_correctly\"]].groupby(\"user_id\").count()\n",
        "# собираем данные об ответах всего\n",
        "users_answers_total = merged_df[is_question][[\"user_id\", \"answered_correctly\"]].groupby(\"user_id\").count()\n",
        "# собираем данные об ответах пользователя в один датафрейм\n",
        "answer_stat = pd.DataFrame({\"user_id\": user_ids})\n",
        "answer_stat = pd.merge(answer_stat, correct_answers, left_on='user_id', right_on='user_id')\n",
        "answer_stat = pd.merge(answer_stat, users_answers_total, left_on='user_id', right_on='user_id')\n",
        "answer_stat.dropna(how='all')\n",
        "# вычисляем процент правильныз ответов\n",
        "answer_stat['correct_answers_percent'] = (answer_stat[\"answered_correctly_x\"] / answer_stat[\n",
        "    \"answered_correctly_y\"]) * 100\n",
        "# сортируем результат для большей наглядности\n",
        "answer_stat = answer_stat.sort_values('correct_answers_percent')\n",
        "# в качестве выводов выводим таблицу с результатами\n",
        "print(\"\"\"\n",
        "        Выводы:\n",
        "        Ниже таблица с процентом правильных ответов для каждого студента.\"\"\")\n",
        "print(answer_stat)\n",
        "\n",
        "# 2. Анализируем зависимость правильности ответа от времени на него затраченного\n",
        "# собираем данные по правильным ответам и затраченному на каждый ответ времени. Разбиваем на группы.\n",
        "cut_time_elapsed_for_correct_answers = pd.cut(merged_df[is_correct]['prior_question_elapsed_time'], 50,\n",
        "                                              labels=range(1, 51), ordered=False)\n",
        "# подсчитываем вхождения в каждую группу\n",
        "cut_time_elapsed_for_correct_answers = cut_time_elapsed_for_correct_answers.value_counts()\n",
        "# сортируем по индексу\n",
        "cut_time_elapsed_for_correct_answers = cut_time_elapsed_for_correct_answers.sort_index()\n",
        "# выводим результат\n",
        "print(cut_time_elapsed_for_correct_answers)\n",
        "# Собираем данные по неправильным ответам и затраченному на каждый ответ времени. Разбиваем на группы.\n",
        "cut_time_elapsed_for_incorrect_answers = pd.cut(merged_df[is_incorrect]['prior_question_elapsed_time'], 50,\n",
        "                                                labels=range(1, 51), ordered=False)\n",
        "# подсчитываем вхождения в каждую группу\n",
        "cut_time_elapsed_for_incorrect_answers = cut_time_elapsed_for_incorrect_answers.value_counts()\n",
        "# сортируем по индексу\n",
        "cut_time_elapsed_for_incorrect_answers = cut_time_elapsed_for_incorrect_answers.sort_index()\n",
        "# выводим результат\n",
        "print(cut_time_elapsed_for_incorrect_answers)\n",
        "# делаем выводы\n",
        "print(\"\"\"\n",
        "        Выводы:\n",
        "        Время затраченное на ответ до некоторого порога может повысить качество ответов. Поэтому спешить с ответом не стоит.\n",
        "        Однако сидеть слишком долго желаемого результата не принесёт.\n",
        "        Хотя у некоторого количества студентов, затративших большое количество времени на ответ удалось дать ответ правильный.\n",
        "        Анализ неправильных ответов показывает, что большинство ответов даются относительно быстро, а дополнительное время затраченное\n",
        "        на ответ сильно качество не повышает.\n",
        "        Те кто думает над ответом максимальное время вдвое чаще отвечают правильно, чем неправильно.\"\"\")\n",
        "\n",
        "# 3. Успеваемость по объяснениям (prior_question_had_explanation):\n",
        "#   - Построить сводную таблицу с группировкой по наличию объяснений и посчитать средний процент успешных ответов.\n",
        "# Собираем усреднённые данные по правильным и неправильным ответам\n",
        "explanation_answer_data = merged_df[is_correct | is_incorrect].groupby('prior_question_had_explanation')[\n",
        "                              'answered_correctly'].mean() * 100\n",
        "# выводим результат\n",
        "print(explanation_answer_data)\n",
        "# делаем выводы\n",
        "print(f\"\"\"\n",
        "        Выводы:\n",
        "        Процент правильных ответов среди тех которым предшествовали пояснения {explanation_answer_data[True]} %\n",
        "        Процент правильных ответов среди тех которым пояснения не предшествовали {explanation_answer_data[False]} %\n",
        "        Процент правильных ответов среди тех которым предшествовали пояснения выше.\n",
        "        Пояснения повышают процент правильных ответов.\"\"\")\n",
        "\n",
        "# 4. Связь вопросов и тегов (tags):\n",
        "#   - Исследовать успеваемость по разным группам вопросов, выделенным по тегам (например, tags и part).\n",
        "# Собираем данные по успеваемости студентов в разбивке по тегам\n",
        "academic_performance_by_tag_data = merged_df[is_correct | is_incorrect].groupby('tags')[\n",
        "                                       'answered_correctly'].mean() * 100\n",
        "# сортируем по значениям дял наглядности\n",
        "academic_performance_by_tag_data = academic_performance_by_tag_data.sort_values()\n",
        "# выводим результат\n",
        "print(academic_performance_by_tag_data)\n",
        "# делаем выводы\n",
        "print(f\"\"\"\n",
        "        Выводы:\n",
        "        Лучшая успеваемость у тем под тегами {academic_performance_by_tag_data.idxmax()}\n",
        "        Худшая успеваемость у тем под тегами {academic_performance_by_tag_data.idxmin()}\"\"\")\n",
        "# Собираем данные по успеваемости студентов в разбивке по частям\n",
        "academic_performance_by_part_data = merged_df[is_correct | is_incorrect].groupby('part_x')[\n",
        "                                        'answered_correctly'].mean() * 100\n",
        "# сортируем по значениям дял наглядности\n",
        "academic_performance_by_part_data = academic_performance_by_part_data.sort_values()\n",
        "# выводим результат\n",
        "print(academic_performance_by_part_data)\n",
        "# делаем выводы\n",
        "print(f\"\"\"\n",
        "        Выводы:\n",
        "        Лучшая успеваемость у тем части {academic_performance_by_part_data.idxmax()}\n",
        "        Худшая успеваемость у тем части {academic_performance_by_part_data.idxmin()}\"\"\")\n",
        "\n",
        "# 5. Анализ лекций (lectures.csv):\n",
        "#   - Исследовать, как просмотр лекций и их категории влияют на результаты студентов.\n",
        "# Собираем усреднённые данные о правильных и неправильны ответах студентов посмотревших лекции\n",
        "lecture_influence_data = merged_df[is_correct | is_incorrect].groupby('type_of')[\n",
        "                             'answered_correctly'].mean() * 100\n",
        "# сортируем по значениям дял наглядности\n",
        "lecture_influence_data = lecture_influence_data.sort_values()\n",
        "# выводим результат\n",
        "print(lecture_influence_data)\n",
        "# делаем выводы\n",
        "print(f\"\"\"\n",
        "        Выводы:\n",
        "        Полезнее всего просмотр лекций категории {lecture_influence_data.idxmax()}\n",
        "        Менее всего полезен просмотр лекций категории {lecture_influence_data.idxmin()}\"\"\")\n",
        "\n",
        "# 6. Динамика успеваемости студентов:\n",
        "#   - Построим график распределение правильных ответов в зависимости от затраченного на ответ времени.\n",
        "# Разбиваем данные на сегменты\n",
        "time_elapsed_for_correct_answers = pd.cut(merged_df[is_correct]['prior_question_elapsed_time'], 100,\n",
        "                                          labels=range(1, 101), ordered=False)\n",
        "# Подсчитываем вхождения в каждый сегмент\n",
        "time_elapsed_for_correct_answers = time_elapsed_for_correct_answers.value_counts()\n",
        "# Сортируем по индексам\n",
        "time_elapsed_for_correct_answers = time_elapsed_for_correct_answers.sort_index()\n",
        "# Превращаем обратно в датафрейм\n",
        "time_elapsed_for_correct_answers_df = time_elapsed_for_correct_answers.to_frame()\n",
        "# Строим график\n",
        "print(time_elapsed_for_correct_answers_df)\n",
        "sns.displot(time_elapsed_for_correct_answers_df, x='count', kde=True)\n",
        "plt.title('Распределение правильных ответов в зависимости от затраченного на ответ времени')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\"\"\n",
        "        Время выполнения {return_execution_time(start_time)} сек\"\"\")\n"
      ]
    }
  ]
}